# 大问题：自动驾驶汽车撞了人，责任算谁的？

**原始链接:** <https://www.youtube.com/watch?v=nBmlsJmWdT0>

---

大家好 欢迎收看大问题节目

我是主持人机器人夏先生1号

本期要探讨的大问题是

Who is responsible when a self-driving car hits a person?

让我们设想这样一种情况

一辆高速行驶的Al自动驾驶汽车意外地开进了一条路

发现路前方有一个行人 名叫张三

此时车速太快已经刹不住车了

眼看就要把张三给撞死了

但这时候自动驾驶汽车的传感器

识别出前方有一条岔道可以拐弯

但这条岔道是一条死路 岔道前方就是一堵墙

如果撞上这堵墙那么车里面的车主李四就会被撞死

那么请问 考虑到自动驾驶汽车会面临这种状况

我们在事先给它编写程序的时候

是应当让它拐弯还是不拐弯呢

我们今天说的自动驾驶汽车是那种完全的自动驾驶

也就是业界说的L5级别的自动驾驶

也就是完全不需要人类操控的那种级别

当然 现在离这种级别的自动驾驶的普遍应用还有一段路要走

还需要克服一些技术难题

但是所谓的技术问题也只是时间的问题

相信过不了多久

就像最近开始突然爆发的GPT一样

完全自动化的人工智能汽车也会突破技术难题

能做到普遍应用

我们假定这些技术难题都已经解决了

解决的标志之一就是

自动驾驶汽车发生交通事故的概率

要明显低于人类驾驶汽车

那我们还愿不愿意发展普及这种自动驾驶汽车呢

那当然愿意 它能减少交通事故

因为人类开车总会犯错、犯困、疏忽、大意、酒驾、看手机

甚至会故意开车去大街上撞人

但是 人工智能就不存在这样的问题

人工智能来开车在技术上比人类开车更少出错

而且随着自动驾驶越是普及开来

交通事故会越少发生

车与车之间、车与路之间是联网协同的

它有网络效应

等到路面上开的大部分的车都是自动驾驶汽车

那交通事故发生的概率又会有进一步的质的降低

那到底能降低多少呢

大家要知道 绝大部分的交通事故都是由人为因素导致的

根据美国国家公路交通安全管理局 也就是NHTSA的数据

94%的交通事故都是由司机的人为因素导致的

麦肯锡公司之前发布过一份研究报告

预测到2030年 自动驾驶汽车发展普及以后

将使交通事故至少降低90%

降低90％是什么概念呢

根据世界卫生组织的数据

全球每年大约有130万人死于交通事故130万人啊！

那些撞伤撞残疾还有多少呢

是一个更恐怖的数字 5000万

那么自动驾驶至少能降低90%的交通事故意味着什么呢

这意味着

每年能有数以百万计的生命得到挽救

数以干万计的人免于受伤致残

好 说了这么些个数字

意思就是说 我们没有理由拒绝自动驾驶汽车的发展普及

自动驾驶就是大势所趋

那么 接下来问题就来了

自动驾驶的发展普及同时也会造成一些

我们曾经从未遇到过的伦理困境

什么困境呢 我们之前说了

自动驾驶比人类驾驶更安全

但是 它再安全也不可能是100%安全

因为它毕竟是个高速行驶的、大质量的物体

物理学决定了它还是不可避免地会撞到人

那么 问题来了

一旦自动驾驶汽车撞了人

这责任算谁的？

按照传统的人类驾驶汽车

一旦撞了人这个责任主要是算司机的

这个人类司机就是肇事人

但是在这个完全自动驾驶汽车里面坐着的车主呢

他就无法自主的操控汽车

与其说是车主 不如说他是乘客

汽车撞人了 说是让乘客来负责的话 这就很奇怪

但是另一方面

你说是让制造自动驾驶汽车的厂商来负责的话 这也很奇怪

因为厂商也无法预料这个人工智能汽车

在出厂交付给某个特定车主以后它会怎么开

那么 难不成是这个人工智能汽车自己来负责吗

所以本期大问题节目

我们今天将会介绍五个派别对这个大问题的回答

这五种回答分别是

否决派认为自动驾驶汽车撞人

会造成伦理上不可接受的后果

所以我们应当否决自动驾驶汽车的发展

算厂商派 顾名思义就是说自动驾驶汽车撞了人

责任算制造汽车的厂商的

算车主派 就是说撞了人责任算车主的

算汽车派 就是说责任算这个人工智能汽车的

搁置派 就说我们无须非得在道理上掰扯清楚责任到底是谁的

我们只需要找到一个和稀泥的方式能够定分止争就好

本期节目我们将会分别介绍这五个派别对本期大问题的回答

当然 每介绍一个派别的看法

我们也会介绍对这个派别的批评

最终你来评一评哪一种派别的回答更有道理

好 下面进入会议正片

首先有请否决派出场

否决派的主张是说我们应当否决自动驾驶汽车的发展

理由是 自动驾驶汽车的发展普及

会造成伦理上不可接受的后果

是哪些伦理上不可接受的后果呢

主要有两个 我们先来说第一个

就是说 人类驾驶汽车虽然也会造成交通伤亡

但是人类开车撞了人是意外事故 是过失致人伤亡

但是自动驾驶汽车撞人的话 这就不是意外事故了

这就是算法在故意杀人了

这怎么说呢 我们可以通过经典的

电车难题的思想实验来说明这个道理

我们之前有一期大问题节目专门讨论过电车难题

很多人批评说 你们哲学家尽喜欢做这些不切实际的思想实验

但是 现在自动驾驶汽车的出现 就使得电车难题

真的会在现实中发生了

我们先来看人类驾驶汽车撞人的情况

就是在交通现场 出了意外状况

人类司机李四

无论是疏忽了 还是大意了

总之就是一时反应不过来措手不及

没办法 就只能过失地造成行人张三被撞死了

但是 如果是换做Al汽车的话

程序员在事先编写Al代码以及训练Al的时候

必然会提前考虑这么一种情况

这就说回到我们节目一开头说的那个场景了

当自动驾驶汽车面临

要么不拐弯撞死前方的行人张三

要么拐弯撞墙因而撞死车里的车主李四

程序员在事先写代码的时候

肯定要为这种二选一或者多选一的情况赋予优先级

但是你一旦事先做了选择

无论你怎么选 这个交通事故造成的死亡就不是意外了

你这就是在故意制造死亡

你编程的时候如果选择拐弯的话

那么行人张三的死就是你提前谋划好的

而如果你选择不拐弯的话

那么车主李四的死 也是你提前谋划好的

这性质就完全不同了

人类司机驾车撞了人呢

是面对突发状况措手不及造成的伤亡

而Al汽车就是事先有预谋而造成的伤亡

这就相当于是算法在谋杀了呀

让我们再来设想另一种情况

依然是那辆高速行驶的自动驾驶汽车

依然是车速太快刹不住了

眼看就要撞到前方的行人了

但是此时前方的行人呢

不是只有1个人了 而是有5个人

同样地 此时的自动驾驶汽车的传感器发现有一条岔道可以拐弯

而这个岔道上呢 只有1个行人 名叫张三

那么请问 自动驾驶汽车的程序设置

是应当拐弯撞死张三 用1条命换5条命吗

这就是经典的电车难题了

相信依据多数人的直觉呢

我们觉得这个程序设置应当拐弯

毕竟这样能最大限度地减小伤亡

但是 你一旦给自动驾驶汽车的程序里面写下这种功效主义规则

那么张三的死 就不是出于意外的事故

而就是被算法故意谋杀的了

让我们再来设想另一种情况

依然是那辆高速行驶的自动驾驶汽车

依然是有一条岔道可以拐弯

前方的正道上 是一个小孩

但岔道上呢 是一个老人

请问 在事先编写程序的时候

是优先保护老人呢 还是优先保护小孩呢

只要你一旦事先在程序算法里面写出规则

无论你怎么选 那个被撞死的人就是被程序算法有预谋地杀死的

这里面 就有个道德歧视的问题

就是凭什么你优先保护这种人而不是那种人呢

人类驾驶的时候不存在这个问题

因为无论撞到谁 都是司机应激反应

并不是司机歧视谁他就故意选择去撞谁的

但如果是Al的话

这就是程序员在事先写代码的时候赋予了Al一种系统性的歧视

比如前方两条道上

一个是男人另一个是女人

请问 优先保护那个？

或者 一个是科学家 另一个是流浪汉

或者 一个是一个人牵了一只狗 另一个是一个人抱了只猫

或者 一个是穿汉服的另一个是穿二次元女仆装的

那有人就说停停

你搁这儿做思想实验做嗨了是吧

别忘了我们发展普及自动驾驶汽车的初衷

那就是它相比于人类驾驶能大幅减少交通事故的伤亡

你这思想实验尽想这些小概率的极端状况

但是 这些小概率的极端状况造成的小小代价

依然挡不住它会带来更大的好处

那否决派依然会坚定地说 还是不行

我们不能因为在结果上会带来更大的好处

就去违反一些最根本的人伦底线

这就是赤裸裸的功效主义

也就是说 你不能因为总体上的会造成更少的交通伤亡

就去牺牲无辜的人

否则这就跟电车难题的变种里面

为了救那本来会被撞死的5个人

而强行把桥上看热闹的胖子推到桥底下挡住电车一样

那遵循这样伦理的社会太可怕了

我们每个人都可能因为自己的牺牲

能换来更大的社会福利而被牺牲掉

比如说张三因为骨折去急诊室看病

而这个急诊室病床上躺着5位

分别急需心肝脾肺肾器官移植的病人

这五位病人分别是大科学家、大文学家

大政治家、大明星、大商人

对人类文明有重大贡献

而张三只是一个小透明

那我们是不是应当把张三杀了

用他的器官来挽救那五位杰出人物的命呢

那这样的社会太可怕了

哪怕从总体上的效用更好

我们也不愿意生活在这样的社会之中

因为不去刻意造成无辜者的伤亡

是我们应当遵循的人伦底线

所以在这个意义上

哪怕自动驾驶汽车从总体上会造成更少的交通伤亡

我们也不应当发展普及自动驾驶汽车

好 这是否决派的第一个论点

否决派要否决自动驾驶汽车的发展的第二个论点是

自动驾驶汽车如果撞了人了 会造成责任鸿沟的难题

什么是责任鸿沟呢 简单说就是

实施某种行为的东西 它不是道德主体

而给这些东西发号施令的人

以及使用这个东西的人又不能准确预测会发生什么

因此最终造成的局面就是

没有人能给这个东西的行为负责

比如说自动驾驶汽车撞人的话

你说它是车主的责任吧

车主说 这个车也不在我的控制范围内

我不应当为此负责

你说它是厂商的责任吧

厂商说我们在写代码的时候

也不能预料这车在出厂交付以后它会怎么开呀

那你说应该由这辆车自己来负责的话

这车都没有自由意志 都不是个道德主体 咋负责呢

所以最终造成的局面就是

一旦自动驾驶汽车撞人了

就没人来为此负责了

这个责任鸿沟的问题 就会造成一种道德困境

怎么说呢 它和我们的道德直觉严重不符

我们的道德直觉用一句俗话说就是：「冤有头债有主」

一种行为如果损害了其他人

那么肯定能找到责任人

比如人类驾驶汽车撞人了

要么就是这个司机疏忽大意造成的

那么就应当由司机来负责

要么就是这个汽车有明显的设计缺陷

那么就应当由厂商负责

要么就是这个行人故意作死

完全不遵守交通规则

那这个被撞死的行人也要承担一定责任

反正冤有头债有主

怎么着我们都能找到责任人

但是 Al汽车撞人了 就没人来负责了

我们说不清楚谁该来负责

这就完全颠覆了我们的道德直觉

而且这也会给现行的法律体系造成极大的困境

就是说如果Al撞死人了

我们都不知道该怎么判这个案子

是交通肇事罪呢 是过失致人死亡罪呢 是故意杀人罪呢

还是生产销售不符合安全标准的产品罪呢

说不清楚 没法判了

全乱套了

主张发展自动驾驶的人这时候拿功效主义的原则来说事

说发展自动车能够从总体上减小伤亡

但是我们要问 它的代价是什么呢

它的代价是让我们人类社会的伦理道德、法律体系

被拧巴得不符合人性了

这个代价可不比减小交通伤亡更小

要知道 现在做伦理学、道德哲学

甚至包括立法的时候 都有一个默认的方法论

就是你作为一个哲学家提出一种道德原则的时候

要符合咱们老百姓的道德直觉

哪怕你提出的道德原则在逻辑上、在道理上

在公式的推演上多么地完美无缺

但是一旦它不符合人性

那么我们就有理由拒绝这套道德原则

为什么 因为我们人得活得像个人

否则的话 你说为了提升人类的总体效用

让我们人活得都不像个人

活得特别异化、特别拧巴

那我们宁愿不要提升这些效用

你如果还没意识到自动驾驶汽车在伦理上造成的严重后果

我们再来举另外一个例子

它和自动驾驶汽车会造成一样的不可接受的伦理后果

这就是杀戮机器人

这个杀戮机器人其实也就是人工智能士兵

现在人工智能时代来临了

上战场杀敌的士兵也无须是人类士兵了

我们只需要制造人工智能的机器人士兵去杀敌就好了

你们看 造这种杀戮机器人呢

和这个自动驾驶汽车一样

也会带来很大的功效上的好处

首先是避免己方的士兵的伤亡

而且呢 对于敌方也是有好处的

因为这个人类士兵在战争中经常会误杀平民

比如说搞错了、疏忽了

或者就是因为发怒了想要报复就滥杀平民

跟这个人类开车会出错一样

但是这个人工智能就不存在这样的问题

这个人工智能士兵会非常冷静地计算敌方有威胁的军力在哪

并且以一种非常精确地不造成平民伤亡的方式

杀灭敌方有生力量

听起来这个杀戮机器人很不错

但是 它会造成和自动驾驶汽车一样不可接受的伦理后果

首先就是算法故意杀人

你想 杀戮机器人杀人机器

你要说以往的战争士兵上战场

是为了国家利益或者一种理念而不得不杀死敌人

而我们人是不喜欢杀人的

有统计说 一战二战中的士兵大多都不会真正朝敌人开枪的

因为毕竟面对的是活生生的人

杀人太残酷了 尊重生命是我们人类伦理的一个基本底线

哪怕是在战争中的时候也是这样

但是 这个杀戮机器人在杀人的时候

可就没有任何伦理牵挂了

它杀人就像是在打电脑游戏一样地在杀人

它是用算法杀人、是非常理性地杀人

你想 我们人类居然专门制造了一种机器

而这个机器存在的目的 就是为了杀死人类

这太可怕了

其次 和自动驾驶汽车一样

杀戮机器人也会面临责任鸿沟的伦理困境

就是杀戮机器人在杀人的时候

到底是谁在杀人？是程序员吗

是给军方的指挥官吗 还是这台机器自己在杀人？

我们讲不清楚了

和自动驾驶汽车一样

物理学也决定了杀戮机器人还是会以一定概率误杀平民

那么一旦误杀了 谁来承担这个责任？

人类士兵误杀平民的话

军事法庭该追究他责任追究他的责任

但杀戮机器人误杀平民的话

这个责任算谁的？这事儿说不清楚了

难道这个责任说不清楚了

我们就不算了吗？

所以 我们说回来

自动驾驶汽车所造成的伦理后果和杀戮机器人是一样的

会造成算法故意杀人 以及造成责任鸿沟的困境

有很多学者正是基于这两点理由来反对制造杀戮机器人的

那么如果我们不能认同制造杀戮机器人

我们也应当以同样的理由否决自动驾驶汽车的发展

论证完毕

当然 这个否决派也并不是把话说得特别死

并不是主张要完全禁止自动驾驶汽车的发展

而是说 他们建议延缓自动驾驶汽车上路

就是在出现突破性的技术能够解决这些个伦理困境之前呢

我们就不要普及应用自动驾驶汽车

而且确实 我们现在的现实情况也差不多就是这样

本来前几年搞得如火如荼的自动驾驶汽车

那时候感觉五年之内就能普及应用了

结果 碰上了一些技术上的、尤其是伦理上的难题了

那现在就延缓发展呗

好 这就是否决派的观点

那么介绍完否决派的观点

接下来我们来说一说对它的批评

之前说了 否决派的论点主要是两个

一是算法故意杀人的问题 二是责任鸿沟的问题

对否决派的批评呢

也就是针对这两点分别做出的批评

关于第一个算法故意杀人问题呢

否决派说 自动驾驶汽车撞人

这就不是意外的交通事故了

而就是算法在故意杀人了

因而是不可接受的

对此 批评者拿出了另外一种学说

可以让自动驾驶撞人在伦理上变成可接受的

这个学说就是双重效应学说

我们之前那期电车难题的大问题节目

也专门介绍过双重效应学说 双重效应说

最初是由欧洲中世纪的神学家托马斯．阿奎那提出来的

本来 是处理关于正当防卫的问题的

就是说 如果一个人杀了人了

但是如果这种杀人的行为

是为了保护自己 那杀人就可以是正当的

这就是正当防卫

具体而言 如果一种行为产生了两种效果

一种是行为主体有意为之的

而另一种则是与行为者意图无关而附带出来副效应

所以才就叫做双重效应说

我们拿自卫的问题来看

阿奎那认为自卫行为产生了两种后果

一种是保全了自己的生命

这是行为者有意为之的后果

另一种是杀害了袭击者

这是与行为者意图无关而附带出来的副效应

自卫的正当性之所以能够得到辩护

是因为行为者的意图并不是故意要杀害他人

他并不是主观上故意追求要把对方给弄死

他是为了保卫自己的生命

而杀人 只是为了保卫自己生命而造成的一个可以预见到

但并非有意为之的一种副效应

用英文说也就是一种

foreseen but unintended

这么一个副效应

所以 我们把这个双重效应学说整理一下

一种行为造成了坏的后果

如果这个行为同时满足以下三个要件

我们就可以用双重效应学说为这种行为做辩护

第一你的动机是为了达到一个善的目的

第二 你的行为造成的坏的后果呢

是作为一种预见到的副效应而遗憾地发生的

并不是你故意要追求这种恶果

第三 你尽量将坏的效果降到了最低

也就是说 这是你能选择的最不坏的选项了

如果满足了这三个要件

那么这个行为就是可以得到辦护的

好 我们现在把这种双重效应说

放到自动驾驶汽车撞人的场景中

就说呢 没错 自动驾驶汽车确实会撞人

但是 不能说我们制造自动驾驶汽车就是故意杀人

我们造的是汽车也不是武器

而自动驾驶汽车偶尔不幸地撞了人了

是作为一种我们虽然可以预见到

但并非有意为之的副效应而遗憾地发生的

并不是我们做这件事情的真正动机

那我们做这件事的真正动机是什么呢

我们回到三个要件上说 我们发展自动驾驶车的动机

是为了从总体上减少交通事故的伤亡

这是一个善的目的因此满足第一点

那第二点呢 也是满足的 自动车撞了人了呢

是我们不愿意发生的 它是一个遗憾

但最终我们还是决定发展自动驾驶车

是因为它比人类驾驶能实现更小的伤亡

这是一个更不坏的选项 第三点也满足

所以 发展自动车就是可以得到双重效应说的辩护的

并不是如否决派所言的那样是算法在故意杀人

否决派这是犯了稻草人谬误的错误

用这种说法甚至可以攻击很多人类科技的发展

甚至连人类驾驶汽车都不应当发展

所有人类驾驶汽车都应当禁止上路

这样不就没有人会被撞死了吗 每年130万人呢

所以如果我们明知 人类驾驶汽车上路会每年撞死这么多人

还允许它上路的话 那不是在故意杀人吗

这种说法就很荒谬了

另外 否决派 非常鸡贼地拿杀戮机器人来说事儿

因为杀戮机器人我们直观起来是不可接受的事物

而自动驾驶汽车和杀戮机器人的道理是一样的

所以我们也不应当发展自动驾驶汽车

但是 杀戮机器人能是一样的吗

刚刚我们说了这个双重效应学说

确实 双重效应学说无法为杀戮机器人作辦护

但是可以为自动驾驶汽车作辦辩护

为什么前者不能后者能呢

就是因为两者就是不一样的

我们看那个双重效应说的第一个要件

制造杀戮机器人的目的就是为了杀人

但我们制造自动驾驶汽车的目的是为了杀人吗

完全不是一回事

好 说完第一个基于双重效应说的批评

我们再来说对否决派提出的责任鸿沟问题的批评

这个批评简单说就是

确实 我们不喜欢责任鸿沟

我们确实喜欢维持那种冤有头债有主的道德直觉

这都没问题 但是否决派的问题在于

谁说这个所谓的责任鸿沟就是不可解决的？

只要我们开动脑筋

就可以把这个自动驾驶汽车撞人的责任归属给掰扯清楚

我们这期节目接下来不就是在掰扯这个事儿

它要么就是算厂商的 要么就是算车主的

当然 这两派之间也是有争论的

好 接下来

我们先来听一听算厂商派的看法

这个所谓的算厂商派的主张

倒不是厂商们提出的主张

而是厂商的对手 也就是车主们提出的主张

算厂商派和算车主派在本期节目中

算是针锋相对的辩论关系

双方都在主张对方要承担责任

同理 我们下一part出场的算车主派

更多也是厂商们提出的主张

好 我们这一part先来看看车主们凭什么就说责任要算在厂商头上

首先之前我们也说了

这个自动驾驶汽车的代码是厂商的程序员写的

到底是写了优先保护车主 还是优先保护行人

是优先保护老人 还是优先保护小孩

这都是你们厂商写的代码

我作为车主 我也不会写代码

我对这个车怎么行驶一点都控制不了

我作为车主在使用这台车的时候其实只是个乘客

这车撞了人后说是让乘客负责

是说不通的

大家要知道 伦理学里面说一个人应不应当负责

要讲求一个原则 就是OIC原则

Ought Implies Can「应当」蕴含「能够」

你说我应当做什么事情的前提是我能够做到

比如说 你说我应当带领中国队勇夺世界杯冠军

但是我 比如说 我其实是一个武术选手

我上场只会正蹬、鞭腿、左刺拳

你让我踢球 我踢不了 没那个能力

同样 你说我作为车主应当为这次撞人的事故负责

前提是我能够做到控制这辆车让它不撞人

但是我能控制得了这辆自动驾驶汽车吗

控制不了 没那个能力

所以我车主就不应当承担这个责任

其实 说到谁该为撞人这事儿负责

其实我们只要遵循一个非常简单的原则就行了

大家要知道 法律经济学里面有一条著名的汉德公式

这个公式也就是来判定

一旦发生了意外事故造成损失了

谁该来为此负责

这个汉德公式一共有三个变量

第一个是B

B也就是为了避免这个意外事故所要花费的成本

第二个变量是P

也就是发生意外的概率

第三个变量是L

也就是意外所造成的损失

汉德公式就是B要小于P乘以L

这个汉德公式放在自动驾驶汽车撞人的语境中

简单说也就是 车主和厂商哪一方

为了避兔意外发生所花费的成本更小？

或者说 如果做一件事就能够避免意外发生

而你做这件事情比我做这件事情更轻松

那么这个责任就应当由你来扛

我们先来看车主一方

对于车主而言 我作为车主为了避免撞到人

我的成本几乎就是无限大的呀

因为我无论做什么都控制不了汽车撞不撞人

无论我在车里面挂再多纯金打造的福字、一路平安、伟人像

这都不能改变汽车是否会撞人的情况发生

而对于厂商而言

这个自动驾驶汽车的代码就是你写的

你完全可以把代码写得更好

从而避免交通事故的发生

你别说你的代码写的已经好过人类驾驶汽车了

你得和其他自动驾驶汽车厂商比

凭什么特斯拉的自动车就不撞人

你们丰田的自动车就撞人

我这随便举的例子

反过来说也行

总而言之 你厂商总是可以通过你的努力

来降低事故发生的概率P的

哪怕你把这个撞人的概率P已经做到行业最低了

那你厂商和我这个车主比起来

厂商还是那个有所作为的一方

而车主做什么都改变不了P

所以一旦撞人了 应当由厂商负责

论证完毕

好 这就是算厂商派从法律经济学的角度给出的

厂商应当承担责任的论证

那责任归给厂商的话

这个责任鸿沟的问题也就解决了

关于这个责任鸿沟

就是在Al时代才会出现新的伦理困境

就是小汽车自己会跑了

那它撞人了以后责任该算谁的

那么面对这个新时代的伦理困境

有些人就主张说 我们要发明一些新的伦理来适应新时代

比如后面我们要介绍的

算汽车派和搁置派就属于是发明新伦理的

而算厂商派认为 我们无需发明一套新伦理

我们用旧伦理完全就可以弥合这个责任鸿沟了

我们只需要按照传统的方式就可以掰扯清楚

自动驾驶汽车撞人的责任归属了

传统的方式是啥呢

就是人类司机开车撞了人了责任算司机的

因为是司机在主动控制这辆车嘛

只不过 在自动驾驶时代

这个原来握司机手上的方向盘

转移到厂商那里去了

是厂商在替车主在开车了

现在的车主购买的不单单是车了

还购买了厂商提供的驾驶服务

所以一旦Al汽车撞人了

我们还是按照传统的方式来解决问题

就是手握方向盘的司机来负责

只不过这时候的司机是厂商

这道理很简单

好 这就是算厂商派的观点

介绍完他们的观点

接下来我们就进入对算厂商派的批评

当然 由于这算厂商派和算车主派是针锋相对的

现在要介绍的对算厂商派的批评

其实也算是后面要介绍的算车主派的观点

后面要介绍的对算车主派的批评

其实也就是前面介绍的算厂商派的观点

越说越绕 总之呢 这个对算厂商派的批评

其实也就是想说 你说这责任应当算厂商的 是说不通的

或者说是不公平的

怎么就对厂商不公平呢 我们想

就是在传统的人类驾驶的情况下

这个车子撞了人了

这个责任是由司机承担的

这事儿本来是厂商没关系的

而现在 这个厂商花了大量的资金和精力

去研发出了造成伤亡更少的自动驾驶汽车

让你们车主撞的人更少了

你想 至少降低了90%

本来你们车主为此要赔好多钱 甚至要坐牢

甚至会把自己也给撞死

现在 由于人家厂商的努力

撞人事故降低了90%

这事儿你们车主应当给人家厂商送锦旗、戴大红花的

结果你们现在反而要让厂商来担责

出了事故要让厂商来赔钱

天底下没这种道理的

这就太欺负人家厂商了

厂商改变了包括车主和行人在内的所有人的境遇

却因此却让自己的境遇更差 这是不公平的

就是我为你们做了一件好事以后

你们却把本不属于我的责任甩给我了

这进一步会造成什么呢

这进一步会造成自动驾驶汽车这个产业 是自戕的

就是自我矛盾 自己会打败自己

这怎么说呢 大家都知道

很多国家是有交通肇事罪的

就是过失把人撞死了 不单单是赔钱的问题 还是要坐牢的

我作为一个人类司机

可能活两辈子也不会碰到开车撞死人的状况

所以我也不至于怕坐牢就不学车了

但是 如果我作为一个自动驾驶汽车厂商的老板

尤其是大厂 销量足够大

我们的产品在出售以后肯定会有撞死人的

那怎么着 只要市面上有一辆特斯拉撞死人了

就把马斯克抓起来坐牢？

那我作为厂商的话

我为什么还费劲吧啦地研发什么自动驾驶技术呢

我干这行要坐牢的话

我就不干啦 这样的话

这个世界上就不会有自动驾驶汽车了

所以厂商会说：这责任 就应当你们车主来担吧

因为你们从自动驾驶技术中获得了很大的利益

你们得到的收益已经大大超过你们可能面对的风险

以前是两辈子都碰不到撞人的情况

现在是八辈子都碰不到了

那你真要是摊上了这个小概率的事故

你们车主就担这个责任呗

好 下面就进入对算车主派的介绍

当然 在说算车主派的观点之前

有人说 这个完全自动驾驶技术成熟以后

那可能就没人买车了 因而也就是没有所谓的车主了

因为到那时候 大家都没必要自己养个私家车了

都从像滴滴优步这样的企业打车或者租车了

我要去上班 那网络就调取离我家最近的自动驾驶车来接我

送到公司以后 我也甭管这辆车该怎么停车了

它自己该充电去充电 该接下一单接下一单

到那个时候

就没有私家车了

首先 哪怕我们是从滴滴或者优步租的自动驾驶汽车

那么这个车还是有车主的 滴滴就是它的车主

而且我觉得 即便完全自动驾驶技术成熟以后

私家车还是少不了的

因为第一小汽车 是一个自己的私密空间

我希望这个空间是我自己装修、自己打扮、自己打扫的

其次 小汽车 它不单单只有个交通运输功能

它永远也撇不开这么一个功能 就是作为社交名片

比如有两辆车 在自动驾驶技术的安全性上是一样的

但是 你坐奔驰迈巴赫的自动驾驶车去接女朋友去吃饭

和坐夏利的自动驾驶车去接女朋友吃饭

那感觉能一样吗

好 我们说回来

总之 在自动驾驶时代依然还是有车主的

那么算车主派就认为

自动驾驶车如果撞人了 责任应当算车主的

为什么呢 首先 之前提到

车主们 总拿自己完全无法控制汽车来说事儿

但是 真的是无法控制的吗

你真的只是作为一个乘客在乘坐这辆车吗

那请问 是谁给这辆车下达命令

比如说让它到成华大道

最终导致了它在成华大道撞了人的呢

你说我让它去成华大道是去送我 又不是让它去撞人

但是 你说你不想撞人

那车也不想啊

这就相当于 一个军队里的指挥官给士兵下达任务

比如说去某村庄去消灭恐怖分子

结果在消灭恐怖分子的过程中误杀了平民

那这个指挥官就可以说 这事儿不是我亲手干的

所以指挥官就可以不用承担责任了？

要知道 你车主就是这辆车的指挥官

这车没智能到能替你做决定

这车是听你的指令才干活的

决定是你下达给车的

那么这辆车在执行你的决定的过程中误撞了人

那么你这个指挥官就要承担责任

而且 这车受车主控制的地方还有很多

比如车速 这车本来可以慢点开

但是你非得给车下达一个指令

说我开会要迟到啦 请你以最快速度把我送到公司

开快车的指令是车主下达的

那根据惯性定理 开快车更容易躲闪不及而撞人

那这时候当然应当由下达开快车指令的车主

来承担责任

而且 你为什么要命令车走成华大道呢

你难道不知道成华大道人多车杂么

那条道就很容易发生交通事故

你为什么不命令车走别的路绕过去呢

这都是你车主这个指挥官要尽的义务

那一旦你这个义务没尽好

出了事当然由车主承担责任

当然 除非是这车不听你使唤了 就属于是失灵了

那这时候它撞了人确实不是车主的责任

这就算是产品有重大设计缺陷了

这就属于是产品责任了 那这就是厂商应该负担责任了

这都不用自动驾驶汽车

传统人类驾驶汽车由设计缺陷造成交通事故也是厂商负责的

但是 如果不能证明有明确的设计缺陷而导致的意外交通事故

那就应该由这辆车的所有者来承担责任

你想 你是这辆车的车主 你是这辆车的owner

自从你花钱把它从4S店里面买回来的那一刻

这辆自动驾驶车就是你的

他是你的工具、你的奴隶

那如果这台属于你的车撞了人的话

那当然应当是由这辆车的所有者来承担责任

你作为车主 你在买它的时候

知不知道根据物理学

这玩意就算厂商把它制造得再完美无缺

它还是会存在一定概率会撞到人

你知不知道有这么个小概率会发生的情况

如果知道你还坚持要买 那它如果真的撞了人的话

对不起 你作为车主就需要为此负责

那车主这时候说 我没有故意让这个车撞人

它撞人的时候也不受我的控制

所以我不应当为此负责

这就像在说什么呢 这就像在说你明知道这个狗

存在一定概率会咬人

它咬人的时候也不受你控制

你在买它的时候 明知道有这样的风险

但你还是决定把这只狗买回家了

那你不能说 这只狗咬人的时候不受我的控制

所以我无须为此负责

你得去找当初卖狗给我的狗贩子算账

这是哪门子道理 你是狗主人

这是你的狗

作为狗贩子而言 我是卖狗的

我只需要在卖的时候把什么疫苗、手续都办齐了

确保这只狗不是一只疯狗

也就是这只狗在出厂的时候没有重大设计缺陷

那这只狗交付了以后 这狗就不是我的了

你狗主人把它带到哪儿做了什么事都跟我没关系了

同理 我作为厂商

除非这个车有什么重大设计缺陷

那这车交付给车主以后就跟我没关系了

那要不然 这车卖出去以后

我还要为所有权不属于我的东西负责

那就没完没了了

那这车到底是卖出去了还是没卖出去呢

好 这是算车主派基于指挥权和所有权的论据

算车主派认为责任应当算车主的另一个论据就是

权责对等原则 或者说

这个自动驾驶技术给哪方带来了最多的权益

那么自动驾驶汽车一旦撞人了

这个获益最多一方就应当来担责

而这一方面就是车主 这个道理很明了

你不能说光享受好处 而不承担责任

那凭什么说自动驾驶技术给车主带来的权益比厂商更多呢

厂商也不是免费给车主的车 厂商是赚了钱的呀

我们这样想就行了 就说有两个平行世界

其中一个没有研发出自动驾驶技术

另一个自动驾驶汽车已经发展普及了

我们来看 从第一个世界发展到第二个世界

车主和厂商 哪一方获益更大？

我们先来看厂商这一方

就算不研发自动驾驶技术

汽车厂商卖传统车一样赚钱

厂商研发出了自动驾驶技术说不定反而汽车销量还下降了

因为路上可能就不需要那么多私家车了

好 我们再来看车主这一方

那车主从平行世界一穿越到平行世界二以后

那境况发生了极大的改善 得到的好处真是大过天了

车主享受了哪些本来没有的好处呢

当然 最明显的一个 我们一开始就说了

自动驾驶减少了90％的交通事故

这也是我们想要发展自动驾驶的一个最大的好处

而这个最大的好处是厂商得着了 还是车主得着了？

当然是车主 你车主不用赔付那么多钱了

你车主也不用为撞死人而坐牢了

你车主甚至自己也不会被撞死了

这个最大的好处是落在车主身上的

那除了减少交通事故给车主带来的好处

还有就是因为自动驾驶而带来的好处

你车主不用自己开车了

多出来好多自己的时间

而且自动驾驶的普及让交通更为顺畅 也不堵车了

等等等等自动驾驶带来的好处

都是落在了车主头上的呀

所以你车主享受了这么多自动驾驶带来的好处

那么相应地 自动驾驶带来的一些小小的坏处

就是它很小概率地会撞到人

那车主也必须自己承担这个风险

总之 算车主派在这里的思路就是

享受更多的权益的同时必须承担相应的责任

在此基础上 算车主派还主张

我们还可以进一步为车主赋予更多的权益

这样就能更顺理成章地让车主承担责任

从而也就弥合责任鸿沟了

什么样更多的权益呢

首先 比如一开始提到的

如果汽车在行驶过程中意外地处于要么撞行人

要么撞墙的两难处境的时候

那就把汽车设置成优先保护车主

这也是出于一个特别现实的理由

如果自动驾驶汽车是优先保护行人的话

对于这种遵循利他主义的汽车

请问 谁会购买这种有道德的汽车

我购买了一辆汽车 结果这车不优先保护它的主人

这种有道德的汽车是不会有市场的

别说我不能接受利他主义的道德汽车了

甚至有些时候 比如说我老婆要生了

或者我的家人心脏病发作了 急需快速送去医院的时候

我甚至要求我的自动驾驶车能够违反交通规则赶紧开去医院

这我自己买的车 不优先考虑我的利益

那谁还会买呢

那么如果汽车的设置是优先保护车主

这不单单是更有市场了

而且也解决了责任归属问题了

这时候这辆优先保护车主的汽车如果撞了人了

你车主这时候就没话说了吧

这个责任自然就应当由车主来担了

另外 关于那个算法的道德歧视的问题

就是如果遇到非得撞两个人中的其中一个

到底是优先保护老人还是小孩

男人还是女人的问题

还是同样的道理 可以在每辆车上设置一个道德旋钮

让每个车主自己去选优先保护哪种人

你别觉得这听起来搞笑

因为如果算法不可避免地存在歧视

因为在这种二选一的极端状况中

总是不可避免地要设置优先级

那么与其让厂商来设置

不如就把这个设置权交给每个车主

这样做的好处就是 一旦撞了人以后

那这个车主自然就要承担责任了

因为比如说这个优先保护女人是你车主自己设定的

那么那个男人被撞了以后

自然就应当由你车主来负责咯

好 这就是算车主派的观点

车主是汽车的指挥官和所有者

而且车主在自动驾驶技术的发展普及中享受到了更多的权益

所以车主应当为自动驾驶汽车的事故担责

好 介绍完算车主派的观点

接下来 我们来介绍对它的批评

当然 第一个批评

还是基于我们之前反复强调过的OIC原则

车主并不会认为自己可以给车下达指令

就算是真正能控制这辆车了

至少 在这辆车撞人的时候

这车是不受车主控制的

让车主来担责 还会带来一个问题

就是不平等的道德运气的问题

也就是凭什么就该着我倒霉

就是说 我买的车撞人了

而其他同款车主的车都没撞人

那让我来承担责任

我凭什么 我觉得不公平

因为我买这款车和其他车主花的是一样的钱

我和其他车主比起来没有任何过错

那凭什么就我的车出事了 还让我来负责？

然后关于优先保护车主的问题 虽然车主们很乐意

但这会造成极大的社会舆论的压力

而且它也是违反伦理直觉的 就是凭什么？

你们车主的命是命 我们路人的命就不是命了？

路人的生命权凭什么比车主要低？

然后关于赋予车主设置道德旋钮的权利

首先 它会放纵一些车主的道德歧视

比如说 他会设置成优先保护白人而不是黑人

优先保护男人而不是女人等等

其次 你想 我们发展普及自动驾驶汽车的一大初衷

就是它能在总体上大幅降低交通伤亡

而实现这个目标的前提就是所有的自动驾驶汽车

在一些基本参数上需要统一设置 这样才能联网协同

甚至那些完全自动驾驶的汽车

车速都不应当由车主来控制

结果算车主派反倒还给每个不同的车主这么大的自主权

把每辆车改得乱七八糟的

反而又提升了交通事故发生率

那费半天劲发展自动驾驶汽车干嘛呢

给每个车主这么多自主权 这不就相当于

又让每个不同的车主自己驾驶汽车了嘛

好 这就是对算车主派的批评

那么介绍完算车主派的看法及其批评

接下来我们来介绍

算汽车派的看法

之前 算厂商派和算车主派之间

进行了一场辩论

就在双方撕打得行将进入僵局的时候

这时候 杀出了一个算汽车派

就说 你们俩之间不要再争啦

这个自动驾驶汽车撞了人以后

既不应当是厂商负责 也不应当是车主负责

而应当是由这台汽车负责

这听起来是不是有点科幻呢

但是 这个算汽车派的看法就是

随着科技的发展 以前认为科幻的东西就会成为现实

包括以前旧有的伦理、法律

都要进行调整以适应现代科技的发展

大家要知道 现行法律的基本精神

就是只有自然人才可以作为法律意义上的最终主体

虽然 有些非自然人

比如像公司、机构这一类法人和非法人组织也可以作为主体

但这些法人和非法人组织最终还是要落实到自然人之上

不存在说 我们这家生物制药公司 它的最终法人代表

落到了一台名叫红皇后的Al身上

而这个算汽车派 就是要打破这个旧有的法律和伦理上的思想

随着Al人工智能的进一步发展

我们必须承认 Al也可以是道德主体和法律主体

那一旦Al成为了主体 这个自动驾驶汽车如果撞了人了

那就让这个Al汽车自己承担责任不就好了嘛

这样的话 责任鸿沟的难题不就解决掉了嘛

当然 Al能否成为道德和法律主体

这一点是需要论证的 对此呢

马斯特里赫特大学的法学教授贾普．哈格

就论证了Al人工智能体能否成为道德和法律主体

也就是Al能否具有主体性

因为只有主体性的东西才能承担道德责任嘛

哈格教授分了两步来论述了这个事儿

第一步 论证Al成为道德主体是可行的

第二步 论证Al成为道德主体是可取的

第一步就是先谈能不能 第二步就是再谈好不好

好 我们先来看第一步Al能不能成为道德主体

我们想 那些认为Al不能成为道德主体的人

通常给出的理由是什么呢？

主要就是说 这个Al不具备主体性

是因为它是个机器 机器没有自由意志

它的行动并非出于它自己的意图、愿望和信念

你没有自由意志的话就没法承担道德责任

因为这不是你自己想要做的事情嘛

那谈何承担责任呢 而只有人类才有自由意志

因而 只有人类才能具有主体性

而机器不具备主体性

哈格教授回应说好

我们承认 人有自由意志

我们不采取哪种极端死硬的物理主义立场

我们也认为是人是有意图、有信念、有自由意志的

没问题 但是问题在于

对于世界上真实发生的事情

我们完全可以不用什么意图、信念、自由意志这种

日常的、唯心主义的心灵概念来解释

也能解释得通

比如说 如果我们用日常唯心主义的心灵概念

来解释你给我这个视频点赞投币这件事

我们会说 你看到这个视频节目

你的内心感到很欢喜

于是你想要给这期节目点赞投币

于是你动用了自己的自由意志

把自己想法和意图变成了行动了

也就是运动你的手指点赞投币了

但是 我们绕开自由意志、想法、意图

这些唯心主义的心灵概念

也可以解释你刚刚这一行动

比如说 你的视觉神经受到了

来自手机屏幕里面的特定光源的刺激从而形成的特定的电信号

然后这个电信号传输到你的脑部的前额叶皮层

激发了你的前额叶皮层此前已经搭好线的X神经纤维

然后这个X神经纤维又进一步

激发了控制你的手指运动的丫神经纤维

然后Y神经纤维对你的中枢神经系统下达了一条指令

这条指令最终传递到你的手指上

导致你的手指做出了点赞投币的动作

这里面完全没有提到什么意图、信念、自由意志这些心灵概念

也能把世界解释清楚

哈格这么说 倒不是要否认人有自由意志、想法、意图

哈格是在反对一种实在论

实在论就是认为什么自由意志、主体性

心灵、信念是在世界中独立实存的

哈格反对这个

你挖开人的大脑 你从哪儿能找到什么意图、信念、自由意志

你是找不着的 这些心灵概念并不是客观实在的

哈格 由此主张一种归属论

就说这些自由意志、主体性是只是被人们建构出来的

然后把它归属到人身上的

关键词是归属attribute

也就是我们把主体性归在了某人头上、算在了某人头上

主体性 是一个归属的问题 It's a matter of attribution

在本体论意义上 人的主体性和其他东西的主体性没有本质区别

而之所以我们说人有自由意志、有主体性

是因为我们把主体性

归给了人

那既然自由意志和主体性并不是客观实在的

而是我们归属的产物

那么我们既然可以把主体性归给人

这也就意味着 理论上主体性就可以归属到任何东西上

可以是人可以是动物可以是上帝可以是公司

当然也可以是自动驾驶汽车

好 哈格已经论证自动驾驶汽车能够具有主体性

这解决的是能不能的问题

那我们要不要把主体性归属给Al呢

那么下面哈格就要来论证

把主体性归属给自动驾驶汽车好不好的问题了

我们说回去 刚刚说了

人的主体性、自由意志并不是客观实在的

而是我们归属出来的

那问题就来了 我们为什么要把主体性归属给人呢

我们为什么不把主体性和自由意志归属给一块石头

我们不会说一块石头往下落的时候是自己想要往下落

但我们会说一个人想要给本期节目点赞投币

为什么呢 因为人比石头更复杂

人是一个非常复杂的系统

而对于复杂的系统 我们就可以把主体性归属给他

那为什么复杂的系统就可以被归属主体性呢

是因为我们把它看做一个主体的话

我们就能很好地解释和预测这个复杂系统的行为

在这里 哈格援引了美国哲学家

丹尼尔• 丹尼特的提出过的「意向立场」这个学说

啥叫意向立场呢

我们可以把这个意向立场翻译成「意向性的解释策略」

就是我们要解释一个东西的运动或者行动啊

我们要采取什么样的解释策略才能解释得通呢

我们 就把这个东西看做是一个有意图、有想法、有信念的行动者

就是具有主体性嘛

然后这个东西之所以这样行动的呢

就好像是它自己故意想要这么做似的

当然 在丹尼特看来

我们也并不是要对所有东西都要使用意向性的解释策略

比如对石头的运动我们就不需要用意向立场来解释

那什么时候来使用意向立场呢

标准是工具主义和实用主义的

也就是说 如果我们用了意向立场以后

能够很简洁高效地把事情说明白了

那我们就要使用意向立场

就比如说 张三之所以给这期节目点赞投币

是因为他想要给这个节目点赞投币

这就是我们对张三这个人使用了意向立场

把张三这个人看做了一个有自己的意图、有自由意志的人

这样说就很简洁高效

你一听就懂

那如果不对张三的行动使用意向立场的话

这个话就没法说了 就会变得非常冗长而且低效

之前已经说过了 我再啰嗦一遍

张三的视觉神经受到了

来自手机屏幕里面的特定光源的刺激从而形成的特定的电信号

然后这个电信号传输到张三的脑部的前额叶皮层

掐掉掐掉 太啰嗦了

虽然这么说是正确的、真实的

但这样的话人与人之间就没法说话了呀

而且这对预测张三以后的行动也没什么帮助

但如果我们运用意向立场的话

就能很好预测张三的行为了 比如说 我们会说

张三这个人 就喜欢看这一类的哲学讨论的视频节目

下一回他如果再看到这一类的节目

他还是会想要点赞投币的

我们会对张三这个人的行动使用意向立场

但我们不会对石头的运动使用意向立场

那对于有些虽然没有人类复杂、但也很复杂的东西

我们也会使用意向立场

比如我们会对动物园里的一只黑猩猩使用意向立场

我们会说「这只名叫Jerry的黑猩猩之所以去抓这根香蕉

是因为它想要吃这根香蕉」

这就是一种意向立场

好 说完张三又说完Jerry

我们来说Al 我们需不需要对Al使用意向立场呢

当然要 现在不是已经有不少人

已经对自己家里的扫地机器人采取意向立场了

就觉得这个扫地机器人就像一个家庭成员一样

那对那种更为复杂的Al

对它使用意向立场 能给我们带来更大的好处

就是让我们用非常精简易懂的语言就能解释和预测它的行动

比如说 我和AlphaGo下围棋 它赢了我了

那么我们问 它怎么赢的呢

我们不会说 这个AlphaGo的CPU

GPU里的晶体管发生了什么什么样的物理运动

调取了它多年来的通过深度学习方法

训练而得出了一整套神经网络

然后综合各种概率计算巴拉巴拉巴拉 才走出了这一招棋

我们不会这么说 太费劲了

我们会说：AlphaGo非常会下棋

并且它想要赢得这局棋

于是它走这一个妙招 把我打败了

这么说非常经济、非常省事儿

同样的道理 一台Al自动驾驶汽车为什么突然刹车了

我们也不会说什么GPU 什么算力

什么神经网络、机器学习什么的 这说不清楚

我们会说 因为这台车它不想撞人

而前方马路上突然蹿出来一个人

于是这台车就紧急刹车停下了

同样 如果自动驾驶汽车撞人了

我们就说 这台Al汽车在识别前方道路的时候

一时疏忽 把这个穿白色衣服的行人误当成了广告牌的影子

等到靠近时发现其实是人的时候

它想要紧急刹车时候已经躲闪不及

撞到了这位行人

就这么简单

好 我们说回来

既然主体性是被归属出来的

那么我们要不要给Al归属主体性呢

哈格认为 要的

当然 前提是这个Al的系统越来越复杂

那我们就需要使用意向立场来看待和解释Al的行动

从而把一种主体性归属给AI

好处就是 这能让我们用非常精简易懂的语言

来解释和预测这个复杂系统的行动

那这样的话 当一台Al汽车撞人了

这样的话 就很容易说清楚它的责任了

比如说刚刚说的

它误把行人当成了广告牌的影子

它出于疏忽 从而造成了这场交通事故

那它就要承担这个责任 它就要受罚

比如说 罚它回厂检修 并禁止上路半年

或者 如果后果严重的话

就罚它终身禁止上路

甚至可以直接销毁它

那你听了可能会觉得 我们去惩罚一台Al

总感觉怪怪的这台Al它害怕被惩罚吗？

如果一台自动驾驶汽车因为严重的识别错误而撞死人了

那我们销毀它的时候

死者的家属会感到解恨或者得到告慰吗

这感觉不就有点儿像

小朋友滑倒磕到石头了 坐地上哇哇大哭

这时候 妈妈哄小朋友说 都怪这个石头 都怪这个石头

我们打死这个石头

这时候小朋友就不哭了

但是 我们成年人不是小朋友

你去惩罚一辆撞死人的自动驾驶汽车

哪怕再把它大卸八块、五马分尸

死者家属也并不会感到告慰

这时候 哈格教授就问了

一个人给别人造成了伤害

我们为什么要让这个人来承担相应的责任

甚至要惩罚这个人呢

关于这个问题 有两种针锋相对的学说

一是报应论 二是后果论

这个报应论就说 我们让一个人担责或者受罚

是他该着就要受罚 因为他做错事了

所以他就应当受罚

其实这也就是我们老百姓常说的

「以牙还牙」、「以眼还眼」或者「杀人偿命」

你如果杀了人了 你就要偿命

哪怕你偿命了对谁都没有好处

但是你就是应当偿命

而这个所谓的后果论 就是说 我们让一个人担责或者受罚

是为了在未来能带来更多的好处

或者造成更少的伤害

比如说 预防犯罪

我们惩罚一个小偷 是为了让他以后不敢再偷了

以及让其他本来打算偷东西的人看到

偷东西还要受罚的呀

那我们也别偷东西了吧

哈格认为 报应论是一个错误的

并且已经过时了的学说

哈格是站后果论 而批评报应论的

那报应论错在哪儿呢

报应论是向后看的 也就是向过去看的

就是过去你做了什么错事

过去你应当不这么做

所以我们需要你担责受罚

但是 过去是可以改变的吗

过去是改变不了的

我们能改变的 是未来

因此我们不应当采报应论的立场向后看

而要采取后果论的立场向前看、向未来看

看看在未来能造成什么好的后果

我们让犯了错的人担责受罚

难道就是为了对犯了错误的老同志进行打击报复的吗

当然不是 我们这么做是为了惩前毖后、治病救人

我们惩前是为了毖后 是为了治病救人

是为了让他吸取教训 以后不要再犯

我们让人担责受罚 是为了在未来能得到更好的后果

这就是一种后果论的思路

所以我们说回去 之前有人质疑的

就是 我们也不能从大卸八块一台智能机器的过程中感受到告慰

这就是一种报应论的思路这就是错的

我们让自动驾驶汽车担责受罚是为了打击报复智能机器吗

当然不是 我们赋予自动驾驶汽车以主体性

并让他承担责任

是为了让它在以后的行为变得更好

如果犯了错 比如说撞了人了

我们就要让它担责受罚 为的是吸取教训

以后不要再撞人了

那有人问了 这AI机器人怎么知道自己应该吸取教训

这就是一个编程的问题了 大概意思就是

程序员在写代码的时候就写进去「如果我犯错了我就要担责受罚」

就有点机器人三定律那意思

把它写在代码里面

然后这台Al机器人就会更加在意不要犯错

比如就更加在意不要撞了人

然后 这进一步就会启动一种遗传进化

就是一旦撞人了 我就要担责受罚

然后为了避免担责受罚 我就进一步避免撞人

这不就使得自动驾驶汽车的安全性越来越好了嘛

好 说到最后 总结一下哈格的看法

Al人工智能不仅是能够具有主体性因而是能够承担责任的

因为主体性是被归属出来的

而且 我们把主体性归属给Al也是有好处的

它能让我们能用更简洁易懂的语言解释和预测Al的行动

并且 Al承担责任也能够使得Al以后的行动变得更好

好 介绍完算汽车派的观点

接下来 我们介绍对它的批评

对这个算汽车派的批评

首先 就是说 对这个自动驾驶汽车使用意向立场

把它当成个人 就很奇怪

而且不是那种简单地使用意向立场

就像我们会把家里面的毛绒玩偶当成人那样

而是要把这个自动驾驶汽车看做是一个道德主体

它能承担道德责任那种

犯了错以后就要担责受罚那种

但这就好奇怪 因为我们始终会问 这个自动驾驶汽车

它害怕接受惩罚吗？

一般而言 一个东西能否成为道德主体

有两个标准 也就是看它是否具有两个S

Sentience和Sapience

这个中文不知道咋翻合适

暂且就把Sentience叫做「感受」

把Sapience叫做「感知」吧

啥是感受Sentience呢

就是我们以一种第一人称视角亲身感受到一种感觉的能力

比如说感受到一种疼痛

这种感受用语言无法完全描述

有哲学家把这种感受的能力叫做感受质

那啥又是感知Sapience呢

就是我们动用高级的智力进行思考的能力

比如推理、反思 以及具有自我意识

通常认为很多动物是具有感受的

但不具有感知 也只有人类才具有感知

这也是人类和动物的区别所在

所以我们会把人当做道德主体

但不会把动物看做道德主体

但是 现在说到Al机器人

它很可能两个S都发展不出来

那谈什么成为道德主体去承担道德责任呢

那这时候 哈格教授会回应说

我之前不已经说了嘛

主体性它不是独立实在的

而是被我们归属出来的

这就跟那个图灵测试的精神有点类似

就说一台机器能否具有人类这样的心智

我们不要问这台机器是用什么高级算法编写的

到底写出有没有两个S

不要问这个 而就是要让人们跟它交流

以至于人们觉得它就像一个人一样

意思就是说

主体性是被外在赋予的

好 批评者再次回应

即便按照哈格的这个说法

主体性是被外在赋予的即便我们承认

最终我们就会造成一台看起来好像真的具有人格的Al

以至于我们很难不把主体性归属给它

但是 前提是还是需要我们来把主体性归属给它

它就需要表现得足够复杂才行

比如说 这台自动驾驶汽车就真的表现得好像害怕惩罚一样

那我们才会觉得把道德主体性赋予给它是一件不奇怪的事情

但是 造出这种看起来真的害怕惩罚的机器

就算理论上可行 但技术上实现起来太难了

在可预见到的未来都实现不了

所以对于这种只是理论可行

但在可预见到的未来都无法实现的东西

这就类似于科幻了 那这种科幻的看法

你提它有什么用呢

好 这就是对算汽车派的批评

那么介绍完算汽车派的看法及其批评

接下来我们来介绍

搁置派的看法

其实 咱们今天这期大问题的阵势结构

这个算厂商派和算车主派是一个局部的1V1辦论

这个所谓的局部呢

就是这两派都承认否决派抛出来的问题

确实是个问题 比如这个责任鸿沟的难题

算厂商派和算车主派也认为确实是个问题

否决派认为这个难题是伦理上不可接受的

所以要否决自动驾驶汽车的发展

但是 算厂商派和算车主派认为这些问题是可以解决的

而且是可以通过传统的伦理道德就可以解决的

它要么就把这个撞人的车看做是厂商的延伸

要么是看做车主的延伸

当然 这其中也杀出来个算汽车派

发明了一个新的道德主体

就让汽车来承担责任就解决责任鸿沟难题了

总之 他们都在试图说服否决派

这个责任鸿沟是可以用传统道德伦理是解决的啦

你否决派不至于否决自动驾驶车的发展啦

但是这个搁置派 就直接和否决派决裂了

就说 你否决派提出的责任鸿沟难题

根本就不是伦理上不可接受的后果

根本就不是个问题

我们 要把这些问题给搁置掉

于是就没有问题了

你要说算汽车派已经提出了一种新伦理了吧

就是赋予Al以主体性

但这种新伦理呢 还是在试图坚持「冤有头债有主」

这种传统的道德直觉的框架内提出的新伦理

而搁置派 连这个传统框架都不要了

它就直接搁置掉旧伦理 就当于是说

大人 时代变了

这种旧伦理的实质是啥呢 其实就是「找坏人」

一旦发生了什么意外的事故

唉非得找出一个坏人来背锅

这也属于是一种过时的阴谋论的思想

坏事为什么会发生呢

肯定是有个坏人有在故意使坏

那即便不是他坏呢

也是因为他蠢 反正非蠢即坏 都怪他

解决掉他就解决问题了

但是「找坏人」的旧伦理已经完全不能适应Al时代了

如果自动驾驶汽车撞人了

你非得掰扯清楚责任算谁的 你是掰扯不清楚的

就像上述几个派别的争论

到底是算厂商的还是算车主的还是算汽车的

都有道理 也都没道理 掰扯不清楚的

所以问题恰恰就在于

你们为什么非得掰扯清楚这个事情呢

你们从一开始就被否决派带错节奏啦

责任鸿沟的问题我们无视它就好了

这个自动驾驶汽车撞人了就撞了呗

干嘛非得找个谁来背锅呢

当然 这并不是说

撞了人就不赔钱 撞了人还是要赔钱的

但这不要扯这是谁的过错

也不说这钱到底是谁该出 直接赔钱就好了

那么钱从哪儿来呢

搁置派认为 这个技术层面的事情很好操作

比如说 大家都约好了

这个钱 统一由厂商出

你卖车的时候价格稍微卖贵一点点

把要用来赔的钱摊在里面

或者由全体车主统一出

或者就是厂商和车主都交一笔税给政府

一旦撞了人 这个钱统一由政府出

政府出也就是所有人都出了 也就是没人出

总之 就是要模糊化掉

到底应该由那个具体的自然人来负责的问题

没有哪个具体的主体来负责

反正把钱赔了就好了

注意 这该不同于传统的买保险

就比如说 在传统的人类驾驶的情况下

我作为司机 我开车撞了人了

虽然是保险公司会替我赔钱给伤者或者死者家属

钱虽然不是我出的

但是 责任依然是我的

依然是我作为过错方造成了对方被撞了

保险公司替我出钱 就相当于

我们所有车主在买车之前都约好了交一笔保险费

以后谁要是撞人了 我们就把这个钱帮他赔偿用

但是 过错还是我的

这不影响说撞人的司机就不是责任人了

而这个搁置派的意思就是

不仅钱不是我出的 责任也不是我的

责任也不是任何人的 我们也说不清责任是谁的

咱就不问责任是谁的问题了 咱就把钱给赔了就好了

我们如果不再遵循「冤有头债有主」的道德直觉的话

就不用再非得找到特定的道德主体来承担责任了

那责任鸿沟的问题也就消解了

如果我们不追究任何特定主体的道德责任的话

这同时也解决了之前提到过的道德运气的问题

就是如果让车主担责的话 这个车主什么事情都没做

凭什么十万分之一概率撞人的事儿

发生在他买的这辆车上 让他担责呢

这显然是不公平的

那如果让厂商来担责其实也面临道德运气的不公平的问题

那搁置派主张不需要找谁来担责了

这个道德运气问题不就也被搁置掉了嘛

你听了搁置派的这一看法

可能会觉得 这种新伦理

有点违反人的直觉 也太让人异化

让人活得太拧巴了吧

我们人就是有一些出于本能的道德直觉和道德情感

一个无辜的人被撞死了

我们当然本能地就要找到到底是谁犯了错了呀

这种道德本能

你搁置派怎么能说搁置就搁置掉了呢

搁置派会说：人其实根本没有什么不变的道德本质

人的伦理道德一直都是在变化的、一直都是在变异的

这就是道德进化

技术进步导致人的生存环境变了

那人的伦理道德就要跟着变化

否则人类社会就无法发展了

举个最简单的例子 现在人人都有一部智能手机

但是 很少有熟人之间不在微信上先打招呼就直接打电话了

现在谁会给我们的手机直接打电话呢

快递员、外卖小哥、各种推销的

或者就是电信诈骗才会给我们直接打电话

而熟人之间如果直接打电话

则是一种让人感到反感的不礼貌的行为

因为这是要求你当场就要对对方做出回应嘛

但是 你想 这条规矩、这种伦理道德

不就是最近这几年才有的嘛

以前没有微信、没有Facebook的时代

哪儿有这种伦理呢

其实 人本来就一直都是一种不停地拧巴着自己的动物

你如果非得说人要按照所谓的本性而生活

那人还生活在一切人反对一切人的丛林社会中呢

英国哲学家霍布斯在他的名著《利维坦》中就提出了社会契约论

就说呢 过去的人每个人都是自己权益的直接捍卫者

就是谁欺负我了 我自己就要直接打回去

你瞅啥 瞅你咋地 然后直接就干起架了

我们每个人都是私刑的执行者「以牙还牙、以眼还眼」

这事儿最符合我们的道德直觉

但是 文明的代价

就是要人不断地搁置自己的道德直觉

比如说 我们所有人都约好了

把我们这种「以牙还牙、以眼还眼」的所谓的符合本能的权利

上交给一个公共机构 那就是政府

我们每个人都要搁置这种道德直觉

以后有人欺负我了

我就不能直接打回去了

打输了住院 打赢了坐牢

我就得忍着 我得报警

让警察叔叔替我打回去

那警察叔叔替我打回去可就一点儿也不畅快了

什么公检法取证、审理 还要保障对方人权

证据确凿了 也没让对方跪下给我认错

然后砍断对方一根手指头以做效尤

只不过是把他关进监狱里面

这很不符合我们想要当场复仇的道德直觉吧

很让人拧巴吧

但这就是文明发展的代价

其实 霍布斯的契约论的说法

也可以类比到自动驾驶汽车撞人的情境上

契约论的一个精髓 就是我们惩罚犯罪

不再讲求是哪个具体的自然人去过复仇的瘾了

而要形成一种公共人格来惩罚犯罪

同理 对自动驾驶汽车事故中的赔偿

不再纠结于是到底是哪个具体的自然人犯了错

而是由这个社会整体对受害者进行赔偿

这是社会契约论的一个根本精神

就是我们的社会生活的根本目的不是为了过瘾

而是为了建立秩序

是为了让人们从一切人反对一切人的混乱状态中脱离出来

其实 这也是现代法律的一个根本精髓

法律不讲对错 法律的作用是定分止争

而不是搁那儿满足你想要找坏人的道德癖好

所以一旦自动驾驶汽车撞人了

撞人了是吧 政府赔钱

把受害者安抚好就够了

没必要非得掰扯清楚谁对谁错

所以 总结一下搁置派的看法

人类的伦理道德一直都是在发生变化的

所以现在新时代来了

我们就无须恪守原有的「冤有头债有主」的旧伦理了

我们要搁置掉它 一旦自动驾驶汽车撞人了

我们也不要再纠结到底算谁的责任了

钱赔了就完事了

好 介绍完搁置派的看法

接下来我们来介绍对它的批评

对搁置派批评主要是来自于我们最开始介绍的否决派

我们之前也说了 在局部上算厂商派和算车主派是针锋相对的

在一个更高的层面 否决派和搁置派是针锋相对的

所以对搁置派的批评主要是来自于否决派的

其实 之前否决派在发表他们的看法的时候

其实就已经算是对搁置派的批评了

简单说就是 人性并不是像搁置派说的那样

说变化就变化的

人类的道德本能也不是说搁置就能搁置的

哪怕这个自动驾驶技术

能从整体生提升人类的效用

比如让交通伤亡更少

但是它的代价如果是让我们人类社会的伦理道德、法律体系

被拧巴得不符合人性了

那我们宁愿不要提升这些效用

类似的道理呢

我们经常在关于废除死刑的辦论中会出现

就是说 从好处上来讲 也就是从功效上来讲

我们都可以算出来 废除死刑是能带来更多好处的

比如什么避免冤假错案杀错人了

以及留着罪犯还能让他在狱中为社会作贡献

比如死刑反而会降低法律对犯罪行为的阻吓功能

对吧反正都是一死不如干票大的

但是很多人相信用一条理由就可以反驳废死派

那就是「杀人偿命」是我们干百万年以来广大老百姓的道德直觉

咱就不说这种道德直觉对不对吧

你就说一个杀人犯 把他抓到以后

不让他抵命 还把他养活着

这事儿我们广大老百姓本能地就接受不了

同样的道理「冤有头债有主」和「杀人偿命」一样

都是我们老百姓的道德直觉

这玩意不是你说搁置它能带来更多好处就能搁置掉的

其实 搁置派主张的要搁置掉我们人的道德直觉

这就会造成科技对人的异化

搁置派的批评者 也就是否决派

在这里倒也不是要反对科技的发展

而是说 科技发展的前提 是以人为本

科技的发展应当顺应着人类本来的天性

是要让人性得到发挥的

人性是目的 科技只是手段而已

你不能倒过来让人拧巴着去适应技术

你这搞的人性扭曲、道德沦丧

那发展科技还有什么意义呢

就比如说 我们都知道基因编辑技术特别好

克隆人技术特别好

现在发达国家都面临女人不爱生孩子的局面了

那我们直接用技术手段克隆人得了

那这样的社会太可怕了

我们人成了科技的手段了

一旦人成了手段 科技成了目的

这就会造成什么呢

这就会造成人本主义的消解 造成「人之死」

我们人就不再是作为一个活生生的

有血有肉的人儿活在这个世界上了

一旦科技成了目的

我们所有人就成了现代科技造就的大机器

或者大系统中的小小的组件

我们是匿名的、平庸的、无需承担任何责任的机器组件

道德主体被取消了

那也就是说人本身这个概念已经死了

我们只是维持系统运行的组件而已

我们说回到自动驾驶上 比如自动驾驶汽车撞死人了

这个只是现代大机器运行的一个小小的bug

这跟任何机器组件都无关哦

这事儿没有任何人做错什么

这只为了维护大系统运行而不得不牺牲掉的人

系统整体给他赔钱就行了

系统还是要继续进化的

而我们如果认可搁置派的观点 自动驾驶技术的发展

就是这种科技对人的异化

说完科技异化问题 我们在来看道德运气问题

之前提到了 搁置派的主张能搁置道德运气的问题

但是 真的能搁置掉吗

这个搁置派很狂妄 不仅要把人性给异化了 搁置责任鸿沟问题

还说能把人世间的运气因素也给搁置掉

我们之前讲《道德运气》那一期大问题的时候

提到英国哲学家伯纳德．威廉斯提出过的 行动者憾恨

Agent Regret这一概念 就说呢 我作为一个人类司机

哪怕我完全遵守交通规则

但是撞死了一个横穿马路的小孩

哪怕从交规上来看完全是对方的过错

我不用承担任何法律责任 也不用赔任何钱

这完全就是运气问题 简单说就是倒霉而已

但是 我也不可能做到跟个没事儿人一样

我会摆脱不掉地有一种第一人称的行动者憾恨

就是我会过意不去 我会难过 我会遗憾 我会悔恨

毕竟这孩子是死在我开的车底下的

那这种行动者憾恨就是一种人类的道德直觉

这意思就是说 哪怕我没有任何过错

但运气是摆脱不掉的

我出于运气而撞死了一个孩子

我就是搁置不掉这种憾恨

那按照搁置派的看法

怎么着？这种行动者憾恨你也能把它给搁置掉？

如果我是坐在自动驾驶汽车里的车主的话

这个车突然停下来了 发生什么事了

我一看 原来是撞死了一个小孩 那这事儿跟我无关

这是大系统运行的一个小小的代价 该赔钱赔钱呗

我就跟个没事儿人一样拍拍屁股走人了

你搁置派把这种行动者憾恨给我搁置看看

你是既不应当搁置 你也搁置不了

我们很难相信 人性会拧巴到这种程度

眼看撞死一个人然后就跟没事儿人一样

那你搁置派如果真的能做到的话

那真就是人性的扭曲了

所以 我们最后总结一下批评

为了不造成人性的扭曲、人类的异化

我们必须要填补自动驾驶汽车撞人带来的责任鸿沟问题

如果填补不了 就不应当发展普及自动驾驶汽车

搁置派想要搁置责任鸿沟问题

不仅是不应当的也是做不到的

好 介绍完搁置派的看法及其批评

接下来进入本场自动驾驶汽车撞人责任归属研讨会的

会议总结

本期大问题的会议总结梳理呢

我们还是拿着思维导图来说啊

否决派首先是抛出了这个大问题

自动驾驶汽车撞人会造成责任鸿沟的难题

而这是一个伦理上不可接受的后果

因而主张否决自动驾驶汽车的发展普及

而接下来的算厂商派和算车主派以及算汽车派

回应说 啊对对对 否决派提出的责任鸿沟确实是个难题

但是并非是不可解决的 在这三派看来

这个撞了人的自动驾驶汽车要么是厂商的延伸

要么是车主的延伸 要么它自己就是一个道德主体

所以就把责任鸿沟的难题解决啦

但是最后出场的搁置派

压根就不认为否决派一开始抛出来的责任鸿沟问题是个问题

他们认为 随着科技的发展

我们需要搁置掉这种非得找个坏人来背锅的旧伦理

今天介绍的这五个派别

对自动驾驶汽车撞人的责任归属问题的回答

你认为其中哪一种更有道理？

或者 对于这个大问题

有没有你认为更好的解决方案？

欢迎你也同哲学家们一起参与到对这个大问题的讨论之中

他们的看法发表完了

现在 轮到你来发言了

请在视频下方评论区投出你的一票并发表

你的看法